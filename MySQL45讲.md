# MySQL45讲

## 1.一条SQL查询语句如何执行？

### MySQLj基本架构示意图

![image-20200207181132597](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200207181132597.png)

- 大体分为**Server层**和**存储引擎层**


### Server层

- 连接器、查询缓存、分析器、优化器、执行器等
- 涵盖大多数核心服务功能和内置函数
- 存储过程、触发器、视图

### 存储引擎

- 负责数据存储和提取
- 架构模式：插件式的，支持InnoDB，MyISAM,Memory等

### 具体步骤

#### 1连接器

- 链接到数据库，连接器负责和客户端建立连接，获取权限、维持和管理连接

- ```mysql
  mysql -h$ip -P$port -u$user -p
  ```

- 连接建立后，即使权限被修改，也不影响已经存在的连接

- 长连接与短连接

  - 长连接：连接成功后，客户端持续有请求，一直使用同一个连接
  - 短连接：每次执行完很少的几次查询就断开连接，下次查询再重新建立一个

- 长连接导致内存涨的快：

  - 临时使用的内存管理在连接对象里，长连接累积下来不释放内存，导致内存占用增长
  - 解决：
    - 定期断开长连接，执行过一个占大内存的查询后，及时断开
    - 通过执行mysql_reset_connection  初始化连接资源

#### 2查询缓存

- 之前如果执行过这条语句，结果会以key-value形式缓存在内存中。key是查询语句，value是查询结果

- 建议不适用查询缓存，每次更新表，缓存的数据都失效了，得不偿失，将参数 query_cache_type 设置成DEMAND，这样对于默认的 SQL 语句都不使用查询缓存  ，对于需要使用的显式指定如下：

- ```mysql
  mysql> select SQL_CACHE * from T where ID=10；
  ```

- MySQL8.0**彻底删除了此功能**

#### 3分析器

- 词法分析，将字符串对应成SQL语句

#### 4优化器

- MySQL已经知道你要干什么
- 决定**多个索引使用哪个索引**；多表关联时决定**各表连接顺序**

#### 5执行器

- 权限判断
- 如果没有优化器来选择具体索引，流程如下：
  - 调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如是则将这行存在结果集中；
  - 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。
  - 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端  

## 2.一条SQL更新语句如何执行？

- 要走与查询语句一样的流程，还涉及两个重要的日志模块
  - 重做日志 redo log
  - 归档日志 binlog

### redo log 

- 每次更新都要写磁盘，磁盘也要查找，IO成本、查找成本都很高
- WAL技术 Write-Ahead Logging ，先写日志，再写磁盘，写记着，等到不忙了再进行写磁盘
- **具体过程**
  - 一条记录要更新，InnoDB先把记录写道redo log，更新内存
  - InnoDB在适当时候，将操作记录更新到磁盘里
  - 若更新记录很多，就要提前将操作记录更新到磁盘里，清空redo log，重新用于记录
  - redo log可以分为4块1GB空间，总大小4GB
  - —————checkpoint——————write pos——————|——————
    - writepos当前记录位置，边写边后移，checkpoint当前要擦除位置，擦除前要将记录更新到数据文件
    - 都是后移且循环的，两者之间是空余部分，一旦writepos追上checkpoint，就满了，必须先擦除，后移checkpoint

### binlog

- redo log 是引擎层InnoDB的日志，binlog是服务层的日志
- 之前没有InnoDB，自带引擎MyISAM没有crash-safe功能
- **区别：**
  - **binlog是server层，所有引擎都能用，redo log是InnoDB特有**
  - **redolog物理日志，记录某个“数据页上做了什么修改”；binlog是逻辑日志，记录的是该语句的原始逻辑 如 “给ID=2的这一行 c字段加1”**
  - **redo log循环写；binlog追加写，写道一定大小会切换下一个，不会覆盖之前日志**

### 具体步骤

```mysql
 mysql> update T set c=c+1 where ID=2
```



#### 1引擎取行

- 执行器先找引擎取ID=2这一行。ID为主键，引擎使用树搜索找到这一行，ID=2若在内存中，直接返回给执行器；否则，从磁盘读入内存再返回

#### 2更新写入

- 执行器拿到行数据，更新值并调用引擎接口写入新数据

#### 3更新redolog

- 引擎将新数据更新到内存，同时操作记录到redo log，redolog prepare状态，告知执行器完成，可以提交事务

#### 4binlog

- 执行器生成此操作的binlog，并写入磁盘

#### 5提交事务

- 执行器调用引擎的提交事务接口，把redo log 的prepare状态改成commit，更新完成

### 两阶段提交

- 将redo log写入拆成 prepare 和commit，为了让两份日志间逻辑一致

- binlog记录的逻辑操作，可以用来恢复数据库
- 两阶段提交为了防止 redolog binlog 只更新一个，另一个没更新的情况
- 



## 3.事务隔离

- **事务支持在引擎层实现**

### 隔离性与隔离级别

#### ACID

- Atomicity 原子性
- Consistency 一致性
- Isolation 隔离性
- Durability 持久性

#### 事务隔离级别

- 读未提交：一个事务还没提交时，它做的变更就能被别的事务看到
- 读提交：一个事务提交之后，它做的变更才能被别的事务看到
- 可重复读：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的
- 串行化：对同一行记录，写加锁，读也加锁，当读写锁冲突时，后访问事务必须等前一个事务执行完成，才能继续执行

**Oracle模式隔离级别为“读提交”**

### 事务隔离实现

**Mysql中，每条记录更新时都会同时记录一条回滚操作。记录的最新值都可以回滚到前一个值**

造成不同时刻启动的事务有不同的read-view，同一条记录在系统中存在多个版本，即数据库的**多版本并发控制（MVCC）**

- **不建议使用长事务**

  - 系统会存在很老的视图，数据库要保存它可能用到的回滚记录，占用大量存储空间
  - 占用锁资源

  

### 事务的启动方式

#### 显式启动事务语句

- begin或start transaction ，提交语句 commit，回滚语句 rollback
- set autocommit = 0 ，这个命令会将这个线程的自动提交关掉。持续存在到主动执行commit或rollback语句或断开连接
- 有些客户端连接框架连接后，会执行一个set autocommit=0，**导致长连接造成长事务**，建议使用set autocommit = 1，显式启动事务

**可以在 information_schema 库的 innodb_trx 这个表中查询长事务，**比如下面这个语句，用于查找持续时间超过 60s 的事务。******

```mysql
select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60  
```

## 4.深入浅出索引（上）

### 索引常见模型

#### 哈希表

- key-value存储数据结构，通过key找对应值value
- key通过哈希函数换算成一个特定位置，但不可避免会出现多个key换算后位置相同的情况
  - 解决方案：
  - 在后面追加一个链表，找到key位置后，如果value值不唯一，那么遍历这个链表，找到真正的value
  - 但这个链表是无序的，增加新value狠快，区间查询却很慢，因为区间查询要扫描一遍，才能完成
- **故 哈希表只适用于等值查询场景**

#### 有序数组

- 等值查询和范围查询都十分优秀；运用二分查找法，时间复杂度O（logn）
- 但插入很麻烦，需要挪动后面所有记录
- 故 **有序数组索引只适用于静态存储索引**

#### 二叉搜索树

- 为了维持O（logn）的查询复杂度，需要保持该树是平衡二叉树
- 但由于索引不止在内存中，还要写到磁盘里，二叉可能会造成树过高，需要的数据块过多，导致查询变慢，所以大多使用N叉树，N取决于数据块大小
- InnoDB整数字段，N为1200，树高为4，就能存1200的3次方个值了，倘若树的一二层都在内存中，访问磁盘的次数不超过2，速度就很快

### InnoDB的索引模型

B+树

![image-20200209141320889](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200209141320889.png)

- 有k个子结点的结点必然有k个关键码；
- 非叶结点仅具有索引作用，跟记录有关的信息均存放在叶结点中。
- 树的所有叶结点构成一个有序链表，可以按照关键码排序的次序遍历全部记录。
- B+树中间节点没有data数据，同样大小磁盘可以容纳更多节点元素
- 查询性能更稳定，适用于范围查询

#### InnoDB中，表都是根据主键顺序以索引形式存放，即索引组织表

- 每一个索引在InnoDB中对应一颗B+树

- 创建一个主键列为ID，表中有字段K的表，且K上有索引

- ```mysql
  mysql> create table T(
  id int primary key, 
  k int not null, 
  name varchar(16),
  index (k))engine=InnoDB;
  ```

- 表中R1~R5的(ID,k)值分别为(100,1)、(200,2)、(300,3)、(500,5)和(600,6)，两棵树的示例示意图如下。

- ![image-20200209141820844](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200209141820844.png)

- 根据叶子节点的内容，索引分为主键索引和非主键索引

  - 聚簇索引（主键索引）：存储整行数据
  - 二级索引（非主键索引）：存储内容是主键的值

- 主键索引，只需要搜索ID这棵B+树；如果二级索引，搜索普通索引树后拿到主键，还要再进行一次搜索，这称为**回表**

### 索引维护

- 如果插入主键值比当前所有主键都大，那么就直接插入；如果值在中间，就要挪动后面的数据。可能会产生页分裂操作，也会降低页的利用率
- 一般建议采用自增主键
- 除非只有一个索引，且是唯一索引，才用非自增字段做索引（key-value）

### 为什么采用B+树?

- 文件大，不可能都放在内存上，要存入磁盘，B+树的结构很适合磁盘读写
- B+树中间节点没有data数据，同样大小磁盘可以容纳更多节点元素
- 可以将所有叶子节点进行串联，遍历即可获取全部数据

## 5.深入浅出索引（下）

### 覆盖索引

**避免回表的一种方法**,例子如下：

```mysql
mysql> create table T (
ID int primary key,
k int NOT NULL DEFAULT 0, 
s varchar(16) NOT NULL DEFAULT '',
index k(k))
engine=InnoDB;

insert into T values(100,1, 'aa'),(200,2,'bb'),(300,3,'cc'),(500,5,'ee'),(600,6,'ff'),(700,7,'gg');

select * from T where k between 3 and 5;
```

每次根据k查出相应ID，还要回表到主键索引B+树上搜索，如果将语句改为

```mysql
select ID from T where k between 3 and 5;
```

只需要查询ID值，ID值存在K索引树上了，可以直接提供查询结果不用回表，这就是覆盖索引

可以建立联合索引来实现 **覆盖索引**，查询条件是**普通索引或联合索引的最左原则字段**，查询结果是**联合索引字段或主键**，都不用回表操作

### 最左前缀原则

以 name_age 联合索引为例，要查询的所有名字第一个字为 “张”，sql语句为"where name like  ‘张%’ "，满足最左前缀就可以用索引加速检索

#### 如何安排索引内的字段顺序？

- **第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。**
  - 如果已经有了(a,b)这个索引，而还需要b索引，不需要a索引，就不用再建立b索引了，直接将(a,b)调整为(b,a)，这样通过顺序调整，少维护了一个索引

### 索引下推

MySQL5.6引入索引下推优化，**对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数**

```mysql
mysql> select * from tuser where name like '张%' and age=10 and ismale=1;
```

**此时下推到 age=10，先把 age不为10的过滤掉，再取回表，减少了回表次数**

### 为什么要重建索引?

有时候因为索引被删除，或者页分裂，导致数据页有空洞，利用率低，重建索引可以将数据重新顺序插入，提高页面利用率，

有时候定期删除早期数据，表的内容很小，可之前的索引却占很大空间，这时用

```mysql
alter table T engine=InnoDB 
```

重建索引，可以节省空间

## 6.全局锁和表锁

处理并发问题

### 锁的分类（按加锁范围）

#### 全局锁

- 对整个数据库实例加锁，语句如下：

- ```mysql
  Flush tables with read lock ;(FTWRL)
  ```

- 无法进行更新，定义的语句或事务

- 典型应用场景：**全局逻辑备份**

- **视图的作用：**

  - 权限控制：某几列允许查询，其他列不允许
  - 简化复杂查询：用视图代替join查询数据，将不同表的字段组合在一起

- 可以通过 可重复读隔离级别开启事务，达到一致性视图的目的

- 对于不支持事务的引擎，只能使用FTWRL，支持事务使用参数 `-single-transaction`即可

- 为什么不用`set global readonly = true`?

  - readonly的值会被做其他逻辑，比如判断库是主库还是备库，修改其值影响很大
  - FTWRL命令后异常断开，MySQL会自动释放这个全局锁，整个库回到正常可更新状态，但设置为readonly后，会一只保持不可写状态，风险较高

#### 表级锁

MySQL中表级别锁有两种：**表锁**和**元数据锁**

##### 表锁

语法：`lock tables ...read/write;`

- 与FTWRL类似，可以用unlock tables 主动释放锁，也可在客户端断开时自动释放

**元数据锁 MDL（metadata lock）**

- 不需要显式使用，默认加的

- 读锁间不互斥，多个线程可同时对一张表进行增删改查
- 写锁间互斥，读写锁间也互斥，一个线程要给表加字段，另一个线程同时也要加/或查询字段，要等到前面的线程执行完才可以

**如何安全给小表加字段？**

- 防止长事务的出现，操作数据库时规定不要长事务；在MySQL的information_schema库的innodb_trx表中，删除对应长事务
- 对于热点表，在alter table语句里设定等待时间，拿不到MDL锁也不要阻塞



## 7.行锁功过：怎么减少行锁对性能的影响？

### 两阶段锁

**两阶段锁协议：**InnoDB事务中，行锁在需要时才加上，但要等到事务结束时才释放

#### 设计标准

如果事务中需要锁多个行，要把最可能造成锁冲突，影响并发度的锁尽量往后放

### 死锁和死锁检测

事务A修改id=2的行，这时事务B修改id=1的行，此时两个事务都在进行中；

然后事务A想要修改id=1的行，事务B想要修改id=2的行，此时两个事务依然都在进行中；

那么两个行都被锁住，且都在等对方释放资源，这就是死锁

- 解决：
  - 直接进入等待，直到超时（参数innodb_lock_wait_timeout来设置）
  - 发起死锁检测，主动回滚死锁链条中某一事务（参数innodb_deadlock_detect= on）
- 一般采取主动死锁检测

#### 热点行导致性能问题

每个新来的线程都向修改同一行，都要判断自己是不是会造成死锁，每次都要进行死锁检测，耗费很大的性能

- 解决：
  - 确保一定不会死锁，临时把死锁检测关掉
  - **控制并发度：可以在中间件中实现**，或者在MySQL中，对于相同行的更新，在进入引擎之前排队
  - 将一行改成逻辑上的多行来减少锁冲突：将1个记录改成10个记录的总和，每次随机更新10个中的1个

## 8.事务到底是隔离的还是不隔离的？

可重复读各级级别，事务T启动时会创建一个视图read-view，这时候其他事务修改数据，事务T看到的依然和启动时一样

![image-20200209175122564](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200209175122564.png)

### 事务的启动时机

- **begin/start transaction 命令并不是一个事务的起点**，在执行到它们之后的第一个操作InnoDB表的语句，事务才真正启动。
- 如果想马上启动一个事务，使用`tart transaction with consistent snapshot`

### MySQL的视图

- 一种是view ：一个用查询语句定义的虚拟表，调用时执行查询语句并生成结果，创建语法create view ...，查询方法与表一样
- 另一个InnoDB在实现MVCC时用到的一致性读视图，即consistent read view ，用于支持**读提交**和**可重复读**隔离级别的实现

### 快照在MVCC里如何工作？

#### 可重复读隔离级别下，事务启动时就“拍了个快照”

- InnoDB中，每个事务有一个唯一的事务ID（transaction ID），事务开始时向InnoDB事务系统申请的，严格按申请顺序递增
- 数据表中每行记录，有多个版本（row），每个版本有自己的row trx_id
- 如下所示，一个记录连续被多个事务更新：

![image-20200209180846201](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200209180846201.png)

**事务启动时，在其启动前的数据版本它认可，在其启动后生成的就不认，必须要找到上一个可见版本（在其启动之前的数据版本）**，找不到就一直往前找

实现：

- InnoDB为每个事务构造一个数组，保存这个事务启动瞬间，当前活跃的所有事务ID，活跃指启动了还没提交
- 数组中，事务ID的最小值记为低水位，系统里面已创建过的事务ID的最大值加一记为高水位
- 这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）
- 数据版本的可见性规则，就是基于数据的row trx_id和这个一致性视图对比结果得到的
- ![image-20200209184120600](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200209184120600.png)
- 对于当前事务的启动瞬间，一个数据版本的row trx_id有以下几种可能
  - 落在绿色部分：已提交事务或当前事务自己生成的，数据可见
  - 红色部分：将来启动的事务生成的，不可见
  - 黄色部分：
    - 若row trx_id在数组中，表示这个版本是由还没提交的事务生成的，不可见
    - 若row trx_id不在数组中，表示这个版本是已经提交了的事务生成的，可见
- 所有数据都有多个版本，实现了”秒级创建快照“

#### 总结

一个数据版本，对于一个事务视图来说，除了自己的更新总是可见外，有三种情况：

1）版本未提交，不可见

2）版本已提交，但是是在视图创建后提交的，不可见

3）版本已提交，而且是在视图创建前提交的，可见

### 更新逻辑



- #### 当前读：

  - 更新数据都是先读后写的，这个读，只能读当前的值，称为”当前读“
  - 当前读只管读当前的真实值，不考虑其他的

- **InnoDB的行数据有多个版本，每个数据版本有自己的row trx_id，每个事务或者语句有自己的一致性视图。普通查询语句是一致性读，一致性读会根据row trx_id和一致性视图确定数据版本的可见性。**

  - 对于可重复读，查询只承认在事务启动前就已经提交完成的数据；
  - 对于读提交，查询只承认在语句启动前就已经提交完成的数据；
  - 当前读，总是读取已经提交完成的最新版本；

## 9.普通索引和唯一索引，怎么选择？

### 查询过程

执行语句

```mysql
select id from T where k=5;
```

在索引树上的查找过程，先从B+树根节点开始，按层搜索到叶子节点，数据页内部根据二分法定位记录

- 普通索引，找到满足条件的第一个记录，还要查找下一个，知道碰到第一个不满足的为止
- 唯一索引，由于定义了索引唯一性，找到第一个满足的就停止检索

实际上，**性能差距微乎其微**，因为InnoDB数据按数据页为单位读写。读一条记录，不是将这个记录从磁盘中读出来，是以页为单位，将其整体读入内存，所以再同一数据页中读下一个记录，耗费的时间可以忽略不计

### 更新过程

#### change buffer：

1.更新数据页时，数据页在内存中，就直接更新；如果数据页不在内存中，在不影响一致性的前提下，InnoDB会将这些更新操作缓存在change buffer中，这就不需要从磁盘中读入这个数据页。

2.当下次查询需要访问这个数据页时，将数据页读入内存，然后执行change buffer中与这个页相关的操作

- change buffer 也可以持久化

3.将change buffer 中的操作应用到原数据页，得到最新结果的过程称为purge。除了访问该数据页会触发purge，系统有后台线程会定期purge。

**好处：**将更新操作先记录在change buffer中，减少读磁盘，语句执行速度明显提升；

数据读入内存要占用 buffer pool，这种方式还能避免占内存，提高内存利用率

- 使用场景：只有普通索引能用，因为唯一索引要先判断表中是否存在重复记录，必须要将数据页读入内存

#### 更新目标页过程：

- 更新的目标页在内存中：

  - 唯一索引找到位置，判断冲突，插入值
  - 普通索引找到位置，插入值

  只是判断与否的问题

- 要更新的目标页不再内存中：

  - 唯一索引需要将数据页读入内存，判断冲突，插入值
  - 普通索引将更新记录在change buffer，结束

  普通索引性能提升明显

### change buffer 使用场景

- 由于真正更新数据的阶段是purge，所以在数据页purge之前，changebuffer 记录的变更越多，收益越大
- 因此，**写多读少的业务**，change buffer效果很好，**比如账单类，日志类**
- 相反的，**写入后马上查询的业务**，change buffer **不太适合**

### 索引的选择和实践

- #### 建议选择普通索引，如果更新后经常查询，就关闭change buffer

### change buffer 和 redo log









