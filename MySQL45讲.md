# MySQL45讲

## 1.一条SQL查询语句如何执行？

### MySQL基本架构示意图

![image-20200207181132597](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200207181132597.png)

- 大体分为**Server层**和**存储引擎层**


### Server层

- 连接器、查询缓存、分析器、优化器、执行器等
- 涵盖大多数核心服务功能和内置函数
- 存储过程、触发器、视图

### 存储引擎

- 负责数据存储和提取
- 架构模式：插件式的，支持InnoDB，MyISAM,Memory等

### 具体步骤

#### 1连接器

- 链接到数据库，连接器负责和客户端建立连接，获取权限、维持和管理连接

- ```mysql
  mysql -h$ip -P$port -u$user -p
  ```

- 连接建立后，即使权限被修改，也不影响已经存在的连接

- 长连接与短连接

  - 长连接：连接成功后，客户端持续有请求，一直使用同一个连接
  - 短连接：每次执行完很少的几次查询就断开连接，下次查询再重新建立一个

- 长连接导致内存涨的快：

  - 临时使用的内存管理在连接对象里，长连接累积下来不释放内存，导致内存占用增长
  - 解决：
    - 定期断开长连接，执行过一个占大内存的查询后，及时断开
    - 通过执行mysql_reset_connection  初始化连接资源

#### 2查询缓存

- 之前如果执行过这条语句，结果会以key-value形式缓存在内存中。key是查询语句，value是查询结果

- 建议不使用查询缓存，每次更新表，缓存的数据都失效了，得不偿失，将参数 query_cache_type 设置成DEMAND，这样对于默认的 SQL 语句都不使用查询缓存  ，对于需要使用的显式指定如下：

- ```mysql
  mysql> select SQL_CACHE * from T where ID=10；
  ```

- MySQL8.0**彻底删除了此功能**

#### 3分析器

- 词法分析，将字符串对应成SQL语句

#### 4优化器

- MySQL已经知道你要干什么
- 决定**多个索引使用哪个索引**；多表关联时决定**各表连接顺序**

#### 5执行器

- 权限判断
- 如果没有优化器来选择具体索引，流程如下：
  - 调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如是则将这行存在结果集中；
  - 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。
  - 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端  

## 2.一条SQL更新语句如何执行？

- 要走与查询语句一样的流程，还涉及两个重要的日志模块
  - 重做日志 redo log
  - 归档日志 binlog

### redo log 

- 每次更新都要写磁盘，磁盘也要查找，IO成本、查找成本都很高
- WAL技术 Write-Ahead Logging ，先写日志，再写磁盘，先记着，等到不忙了再进行写磁盘
- **具体过程**
  - 一条记录要更新，InnoDB先把记录写道redo log，更新内存
  - InnoDB在适当时候，将操作记录更新到磁盘里
  - 若更新记录很多，就要提前将操作记录更新到磁盘里，清空redo log，重新用于记录
  - redo log可以分为4块1GB空间，总大小4GB
  - —————checkpoint——————write pos——————|——————
    - writepos当前记录位置，边写边后移，checkpoint当前要擦除位置，擦除前要将记录更新到数据文件
    - 都是后移且循环的，两者之间是空余部分，一旦writepos追上checkpoint，就满了，必须先擦除，后移checkpoint

### binlog

- redo log 是引擎层InnoDB的日志，binlog是服务层的日志
- 之前没有InnoDB，自带引擎MyISAM没有crash-safe功能
- **区别：**
  - **binlog是server层，所有引擎都能用，redo log是InnoDB特有**
  - **redolog物理日志，记录某个“数据页上做了什么修改”；binlog是逻辑日志，记录的是该语句的原始逻辑 如 “给ID=2的这一行 c字段加1”**
  - **redo log循环写；binlog追加写，写道一定大小会切换下一个，不会覆盖之前日志**

### 具体步骤

```mysql
 mysql> update T set c=c+1 where ID=2
```



#### 1引擎取行

- 执行器先找引擎取ID=2这一行。ID为主键，引擎使用树搜索找到这一行，ID=2若在内存中，直接返回给执行器；否则，从磁盘读入内存再返回

#### 2更新写入

- 执行器拿到行数据，更新值并调用引擎接口写入新数据

#### 3更新redolog

- 引擎将新数据更新到内存，同时操作记录到redo log，redolog prepare状态，告知执行器完成，可以提交事务

#### 4binlog

- 执行器生成此操作的binlog，并写入磁盘

#### 5提交事务

- 执行器调用引擎的提交事务接口，把redo log 的prepare状态改成commit，更新完成

### 两阶段提交

- 将redo log写入拆成 prepare 和commit，为了让两份日志间逻辑一致

- binlog记录的逻辑操作，可以用来恢复数据库
- 两阶段提交为了防止 redolog binlog 只更新一个，另一个没更新的情况
- 



## 3.事务隔离

- **事务支持在引擎层实现**

### 隔离性与隔离级别

#### ACID

- Atomicity 原子性
- Consistency 一致性
- Isolation 隔离性
- Durability 持久性

#### 事务隔离级别

- 读未提交：一个事务还没提交时，它做的变更就能被别的事务看到
- 读提交：一个事务提交之后，它做的变更才能被别的事务看到
- 可重复读：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的
- 串行化：对同一行记录，写加锁，读也加锁，当读写锁冲突时，后访问事务必须等前一个事务执行完成，才能继续执行

**Oracle模式隔离级别为“读提交”**

### 事务隔离实现

**Mysql中，每条记录更新时都会同时记录一条回滚操作。记录的最新值都可以回滚到前一个值**

造成不同时刻启动的事务有不同的read-view，同一条记录在系统中存在多个版本，即数据库的**多版本并发控制（MVCC）**

- **不建议使用长事务**

  - 系统会存在很老的视图，数据库要保存它可能用到的回滚记录，占用大量存储空间
  - 占用锁资源

  

### 事务的启动方式

#### 显式启动事务语句

- begin或start transaction ，提交语句 commit，回滚语句 rollback
- set autocommit = 0 ，这个命令会将这个线程的自动提交关掉。持续存在到主动执行commit或rollback语句或断开连接
- 有些客户端连接框架连接后，会执行一个set autocommit=0，**导致长连接造成长事务**，建议使用set autocommit = 1，显式启动事务

**可以在 information_schema 库的 innodb_trx 这个表中查询长事务，**比如下面这个语句，用于查找持续时间超过 60s 的事务。******

```mysql
select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60  
```

## 4.深入浅出索引（上）

### 索引常见模型

#### 哈希表

- key-value存储数据结构，通过key找对应值value
- key通过哈希函数换算成一个特定位置，但不可避免会出现多个key换算后位置相同的情况
  - 解决方案：
  - 在后面追加一个链表，找到key位置后，如果value值不唯一，那么遍历这个链表，找到真正的value
  - 但这个链表是无序的，增加新value狠快，区间查询却很慢，因为区间查询要扫描一遍，才能完成
- **故 哈希表只适用于等值查询场景**

#### 有序数组

- 等值查询和范围查询都十分优秀；运用二分查找法，时间复杂度O（logn）
- 但插入很麻烦，需要挪动后面所有记录
- 故 **有序数组索引只适用于静态存储索引**

#### 二叉搜索树

- 为了维持O（logn）的查询复杂度，需要保持该树是平衡二叉树
- 但由于索引不止在内存中，还要写到磁盘里，二叉可能会造成树过高，需要的数据块过多，导致查询变慢，所以大多使用N叉树，N取决于数据块大小
- InnoDB整数字段，N为1200，树高为4，就能存1200的3次方个值了，倘若树的一二层都在内存中，访问磁盘的次数不超过2，速度就很快

### InnoDB的索引模型

B+树

![image-20200209141320889](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200209141320889.png)

- 有k个子结点的结点必然有k个关键码；
- 非叶结点仅具有索引作用，跟记录有关的信息均存放在叶结点中。
- 树的所有叶结点构成一个有序链表，可以按照关键码排序的次序遍历全部记录。
- B+树中间节点没有data数据，同样大小磁盘可以容纳更多节点元素
- 查询性能更稳定，适用于范围查询

#### InnoDB中，表都是根据主键顺序以索引形式存放，即索引组织表

- 每一个索引在InnoDB中对应一颗B+树

- 创建一个主键列为ID，表中有字段K的表，且K上有索引

- ```mysql
  mysql> create table T(
  id int primary key, 
  k int not null, 
  name varchar(16),
  index (k))engine=InnoDB;
  ```

- 表中R1~R5的(ID,k)值分别为(100,1)、(200,2)、(300,3)、(500,5)和(600,6)，两棵树的示例示意图如下。

- ![image-20200209141820844](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200209141820844.png)

- 根据叶子节点的内容，索引分为主键索引和非主键索引

  - 聚簇索引（主键索引）：存储整行数据
  - 二级索引（非主键索引）：存储内容是主键的值

- 主键索引，只需要搜索ID这棵B+树；如果二级索引，搜索普通索引树后拿到主键，还要再进行一次搜索，这称为**回表**

### 索引维护

- 如果插入主键值比当前所有主键都大，那么就直接插入；如果值在中间，就要挪动后面的数据。可能会产生页分裂操作，也会降低页的利用率
- 一般建议采用自增主键
- 除非只有一个索引，且是唯一索引，才用非自增字段做索引（key-value）

### 为什么采用B+树?

- 文件大，不可能都放在内存上，要存入磁盘，B+树的结构很适合磁盘读写
- B+树中间节点没有data数据，同样大小磁盘可以容纳更多节点元素
- 可以将所有叶子节点进行串联，遍历即可获取全部数据

## 5.深入浅出索引（下）

### 覆盖索引

**避免回表的一种方法**,例子如下：

```mysql
mysql> create table T (
ID int primary key,
k int NOT NULL DEFAULT 0, 
s varchar(16) NOT NULL DEFAULT '',
index k(k))
engine=InnoDB;

insert into T values(100,1, 'aa'),(200,2,'bb'),(300,3,'cc'),(500,5,'ee'),(600,6,'ff'),(700,7,'gg');

select * from T where k between 3 and 5;
```

每次根据k查出相应ID，还要回表到主键索引B+树上搜索，如果将语句改为

```mysql
select ID from T where k between 3 and 5;
```

只需要查询ID值，ID值存在K索引树上了，可以直接提供查询结果不用回表，这就是覆盖索引

可以建立联合索引来实现 **覆盖索引**，查询条件是**普通索引或联合索引的最左原则字段**，查询结果是**联合索引字段或主键**，都不用回表操作

### 最左前缀原则

以 name_age 联合索引为例，要查询的所有名字第一个字为 “张”，sql语句为"where name like  ‘张%’ "，满足最左前缀就可以用索引加速检索

#### 如何安排索引内的字段顺序？

- **第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。**
  - 如果已经有了(a,b)这个索引，而还需要b索引，不需要a索引，就不用再建立b索引了，直接将(a,b)调整为(b,a)，这样通过顺序调整，少维护了一个索引

### 索引下推

MySQL5.6引入索引下推优化，**对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数**

```mysql
mysql> select * from tuser where name like '张%' and age=10 and ismale=1;
```

**此时下推到 age=10，先把 age不为10的过滤掉，再取回表，减少了回表次数**

### 为什么要重建索引?

有时候因为索引被删除，或者页分裂，导致数据页有空洞，利用率低，重建索引可以将数据重新顺序插入，提高页面利用率，

有时候定期删除早期数据，表的内容很小，可之前的索引却占很大空间，这时用

```mysql
alter table T engine=InnoDB 
```

重建索引，可以节省空间

## 6.全局锁和表锁

处理并发问题

### 锁的分类（按加锁范围）

#### 全局锁

- 对整个数据库实例加锁，语句如下：

- ```mysql
  Flush tables with read lock ;(FTWRL)
  ```

- 无法进行更新，定义的语句或事务

- 典型应用场景：**全局逻辑备份**

- **视图的作用：**

  - 权限控制：某几列允许查询，其他列不允许
  - 简化复杂查询：用视图代替join查询数据，将不同表的字段组合在一起

- 可以通过 可重复读隔离级别开启事务，达到一致性视图的目的

- 对于不支持事务的引擎，只能使用FTWRL，支持事务使用参数 `-single-transaction`即可

- 为什么不用`set global readonly = true`?

  - readonly的值会被做其他逻辑，比如判断库是主库还是备库，修改其值影响很大
  - FTWRL命令后异常断开，MySQL会自动释放这个全局锁，整个库回到正常可更新状态，但设置为readonly后，会一只保持不可写状态，风险较高

#### 表级锁

MySQL中表级别锁有两种：**表锁**和**元数据锁**

##### 表锁

语法：`lock tables ...read/write;`

- 与FTWRL类似，可以用unlock tables 主动释放锁，也可在客户端断开时自动释放

**元数据锁 MDL（metadata lock）**

- 不需要显式使用，默认加的

- 读锁间不互斥，多个线程可同时对一张表进行增删改查
- 写锁间互斥，读写锁间也互斥，一个线程要给表加字段，另一个线程同时也要加/或查询字段，要等到前面的线程执行完才可以

**如何安全给小表加字段？**

- 防止长事务的出现，操作数据库时规定不要长事务；在MySQL的information_schema库的innodb_trx表中，删除对应长事务
- 对于热点表，在alter table语句里设定等待时间，拿不到MDL锁也不要阻塞



## 7.行锁功过：怎么减少行锁对性能的影响？

### 两阶段锁

**两阶段锁协议：**InnoDB事务中，行锁在需要时才加上，但要等到事务结束时才释放

#### 设计标准

如果事务中需要锁多个行，要把最可能造成锁冲突，影响并发度的锁尽量往后放

### 死锁和死锁检测

事务A修改id=2的行，这时事务B修改id=1的行，此时两个事务都在进行中；

然后事务A想要修改id=1的行，事务B想要修改id=2的行，此时两个事务依然都在进行中；

那么两个行都被锁住，且都在等对方释放资源，这就是死锁

- 解决：
  - 直接进入等待，直到超时（参数innodb_lock_wait_timeout来设置）
  - 发起死锁检测，主动回滚死锁链条中某一事务（参数innodb_deadlock_detect= on）
- 一般采取主动死锁检测

#### 热点行导致性能问题

每个新来的线程都向修改同一行，都要判断自己是不是会造成死锁，每次都要进行死锁检测，耗费很大的性能

- 解决：
  - 确保一定不会死锁，临时把死锁检测关掉
  - **控制并发度：可以在中间件中实现**，或者在MySQL中，对于相同行的更新，在进入引擎之前排队
  - 将一行改成逻辑上的多行来减少锁冲突：将1个记录改成10个记录的总和，每次随机更新10个中的1个

## 8.事务到底是隔离的还是不隔离的？

可重复读各级级别，事务T启动时会创建一个视图read-view，这时候其他事务修改数据，事务T看到的依然和启动时一样

![image-20200209175122564](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200209175122564.png)

### 事务的启动时机

- **begin/start transaction 命令并不是一个事务的起点**，在执行到它们之后的第一个操作InnoDB表的语句，事务才真正启动。
- 如果想马上启动一个事务，使用`tart transaction with consistent snapshot`

### MySQL的视图

- 一种是view ：一个用查询语句定义的虚拟表，调用时执行查询语句并生成结果，创建语法create view ...，查询方法与表一样
- 另一个InnoDB在实现MVCC时用到的一致性读视图，即consistent read view ，用于支持**读提交**和**可重复读**隔离级别的实现

### 快照在MVCC里如何工作？

#### 可重复读隔离级别下，事务启动时就“拍了个快照”

- InnoDB中，每个事务有一个唯一的事务ID（transaction ID），事务开始时向InnoDB事务系统申请的，严格按申请顺序递增
- 数据表中每行记录，有多个版本（row），每个版本有自己的row trx_id
- 如下所示，一个记录连续被多个事务更新：

![image-20200209180846201](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200209180846201.png)

**事务启动时，在其启动前的数据版本它认可，在其启动后生成的就不认，必须要找到上一个可见版本（在其启动之前的数据版本）**，找不到就一直往前找

实现：

- InnoDB为每个事务构造一个数组，保存这个事务启动瞬间，当前活跃的所有事务ID，活跃指启动了还没提交
- 数组中，事务ID的最小值记为低水位，系统里面已创建过的事务ID的最大值加一记为高水位
- 这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）
- 数据版本的可见性规则，就是基于数据的row trx_id和这个一致性视图对比结果得到的
- ![image-20200209184120600](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200209184120600.png)
- 对于当前事务的启动瞬间，一个数据版本的row trx_id有以下几种可能
  - 落在绿色部分：已提交事务或当前事务自己生成的，数据可见
  - 红色部分：将来启动的事务生成的，不可见
  - 黄色部分：
    - 若row trx_id在数组中，表示这个版本是由还没提交的事务生成的，不可见
    - 若row trx_id不在数组中，表示这个版本是已经提交了的事务生成的，可见
- 所有数据都有多个版本，实现了”秒级创建快照“

#### 总结

一个数据版本，对于一个事务视图来说，除了自己的更新总是可见外，有三种情况：

1）版本未提交，不可见

2）版本已提交，但是是在视图创建后提交的，不可见

3）版本已提交，而且是在视图创建前提交的，可见

### 更新逻辑



- #### 当前读：

  - 更新数据都是先读后写的，这个读，只能读当前的值，称为”当前读“
  - 当前读只管读当前的真实值，不考虑其他的

- **InnoDB的行数据有多个版本，每个数据版本有自己的row trx_id，每个事务或者语句有自己的一致性视图。普通查询语句是一致性读，一致性读会根据row trx_id和一致性视图确定数据版本的可见性。**

  - 对于可重复读，查询只承认在事务启动前就已经提交完成的数据；
  - 对于读提交，查询只承认在语句启动前就已经提交完成的数据；
  - 当前读，总是读取已经提交完成的最新版本；

## 9.普通索引和唯一索引，怎么选择？

### 查询过程

执行语句

```mysql
select id from T where k=5;
```

在索引树上的查找过程，先从B+树根节点开始，按层搜索到叶子节点，数据页内部根据二分法定位记录

- 普通索引，找到满足条件的第一个记录，还要查找下一个，知道碰到第一个不满足的为止
- 唯一索引，由于定义了索引唯一性，找到第一个满足的就停止检索

实际上，**性能差距微乎其微**，因为InnoDB数据按数据页为单位读写。读一条记录，不是将这个记录从磁盘中读出来，是以页为单位，将其整体读入内存，所以再同一数据页中读下一个记录，耗费的时间可以忽略不计

### 更新过程

#### change buffer：

1.更新数据页时，数据页在内存中，就直接更新；如果数据页不在内存中，在不影响一致性的前提下，InnoDB会将这些更新操作缓存在change buffer中，这就不需要从磁盘中读入这个数据页。

2.当下次查询需要访问这个数据页时，将数据页读入内存，然后执行change buffer中与这个页相关的操作

- change buffer 也可以持久化

3.将change buffer 中的操作应用到原数据页，得到最新结果的过程称为purge。除了访问该数据页会触发purge，系统有后台线程会定期purge。

**好处：**将更新操作先记录在change buffer中，减少读磁盘，语句执行速度明显提升；

数据读入内存要占用 buffer pool，这种方式还能避免占内存，提高内存利用率

- 使用场景：只有普通索引能用，因为唯一索引要先判断表中是否存在重复记录，必须要将数据页读入内存

#### 更新目标页过程：

- 更新的目标页在内存中：

  - 唯一索引找到位置，判断冲突，插入值
  - 普通索引找到位置，插入值

  只是判断与否的问题

- 要更新的目标页不在内存中：

  - 唯一索引需要将数据页读入内存，判断冲突，插入值
  - 普通索引将更新记录在change buffer，结束

  普通索引性能提升明显

### change buffer 使用场景

- 由于真正更新数据的阶段是purge，所以在数据页purge之前，changebuffer 记录的变更越多，收益越大
- 因此，**写多读少的业务**，change buffer效果很好，**比如账单类，日志类**
- 相反的，**写入后马上查询的业务**，change buffer **不太适合**

### 索引的选择和实践

- #### 建议选择普通索引，如果更新后经常查询，就关闭change buffer

### change buffer 和 redo log

- redo log主要节省 随机写磁盘的IO消耗
- change buffer主要节省 随机读磁盘的IO消耗

## 10.MySQL为什么有时候会选错索引？

### 优化器逻辑

**选择索引是优化器的工作**

### 扫描行数的判断

#### 区分度

一个索引上不同值越多，索引区分度越好，一个索引上不同值的个数，称之为“基数”

#### 基数的由来

采样统计，默认选N个数据页，统计页上的不同值，得到一个平局值，乘这个索引的页面数

变更行数超过1/M时，自动触发重新做一次索引统计

**可以用`analyze table t`来修正统计信息，只针对索引统计信息不准确的问题**

优化器认为直接查主键，虽然行数较多，但省去了回表的消耗，有时候这样的决策是错误的

### 索引选择异常和处理

- #### 采用force index 强行选择一个索引

  - 局限性太大

- #### 修改语句，引导MySQL使用我们期望的索引

- #### 新建索引/删掉索引

## 11.怎么给字符串字段加索引

```
mysql> create table SUser(
ID bigint unsigned primary key,
email varchar(64), 
... 
)engine=innodb; 
```

由于要使用邮箱登录，所以业务代码中一定会出现类似于这样的语句：

```
mysql> select f1, f2 from SUser where email='xxx';
```

从第4和第5篇讲解索引的文章中，我们可以知道，如果email这个字段上没有索引，那么这个语句就只能做全表扫描。

比如，这两个在email字段上创建索引的语句：

```
mysql> alter table SUser add index index1(email);
或
mysql> alter table SUser add index index2(email(6));
```

**第一个语句创建的index1索引里面，包含了每个记录的整个字符串；**

**而第二个语句创建的index2索引里面，对于每个记录都是只取前6个字节**

**前缀索引占用空间小，但可能会增加额外的记录扫描次数**

### 前缀索引使用

- 定义好长度，就既能节省空间，又不用额外增加态度查询成本

- 让前缀索引在尽可能短的情况下区分度尽量高

- 首先，你可以使用下面这个语句，算出这个列上有多少个不同的值：

  ```
  mysql> select count(distinct email) as L from SUser;
  ```

  然后，依次选取不同长度的前缀来看这个值，比如我们要看一下4~7个字节的前缀索引，可以用这个语句：

  ```
  mysql> select 
    count(distinct left(email,4)）as L4,
    count(distinct left(email,5)）as L5,
    count(distinct left(email,6)）as L6,
    count(distinct left(email,7)）as L7,
  from SUser;
  ```

  当然，使用前缀索引很可能会损失区分度，所以你需要预先设定一个可以接受的损失比例，比如5%。然后，在返回的L4~L7中，找出不小于 L * 95%的值，假设这里L6、L7都满足，你就可以选择前缀长度为6。

### 前缀索引对覆盖索引的影响

**使用前缀索引就用不上覆盖索引的优化功能**，因为它必定要回表查当前主键对应的行中当前的索引值是否完全相同而不是只有前缀相同

### 其他方式

以存储身份证号为例，如果管理的是一个市的公民信息系统，那么身份证号前6为区分度为0，因此前缀索引很难发挥

#### 倒序存储

将身份证号倒过来存储

#### 使用hash字段

使用crc32()函数，将身份证号变为校验码字段存储，再以校验码为索引

#### 注意：都不支持范围查询，只支持等值查询

#### 区别：

- 占用额外空间：倒序存储方式在主键索引上，不会消耗额外存储空间
- CPU消耗：reverse函数额外消耗CPU资源比crc32函数小
- 查询效率：hash字段方式查询更稳定，倒序存储本质还是前缀索引，还是会增加扫描行数

## 12.为什么我的MySQL会“抖”一下？  

**当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。**

**内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”**  

平时执行很快的更新操作：写日志和内存

抖动：刷脏页

### 刷脏页的时刻

#### redo log 写满

checkpoint移动，移动区间所有脏页都要flush进磁盘

#### 内存不足

淘汰数据页，给新数据页使用

#### 系统空闲时刻

#### MySQL正常关闭

### 四种时刻分析

- 第一种“redo log 写满”，尽量避免，此时不接收更新，阻塞

- 第二种“内存不足”，是常态，InnoDB用缓冲池（buffer pool）管理内存，缓冲池内存页的三种状态
  - 还没有使用
  - 使用了且干净页
  - 使用了且脏页
- 影响性能的刷脏页操作：
  - 查询要淘汰的脏页个数太多，导致查询影响时间明显变长
  - 日志写满，更新全部堵住，写性能跌至0

### InnoDB刷脏页的控制策略

`innodb_io_capacity   `参数，对应磁盘的IOPS，尽全力刷脏页

考虑：

- 脏页比例 `innodb_max_dirty_pages_pct  `脏页比例上限，默认值75%，不要让它经常接近75%
- redo log 写盘速度

### 其他

`innodb_flush_neighbors`：刷脏页时，如果这个值为1，会找到邻居脏页一起刷掉，且这个逻辑可以蔓延

- 对机械硬盘优化较大，减少随机IO
- SSD这种IOPS较高的设备，IOPS不是瓶颈

## 13.为什么表数据删掉一半，表文件大小不变？ 

### 参数`innodb_file_per_table`

表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数`innodb_file_per_table `控制的：

- 这个参数设置为 OFF 表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起
- 这个参数设置为 ON 表示的是，每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中

一个表单独存储为一个文件更容易管理，不需要时，直接drop table，会直接删除这个文件；如果放在共享空间，表删掉了空间也不会回收

推荐设置为 ON

### 数据删除流程

![image-20200213150330269](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200213150330269.png)

如果删除R4这个记录，InnoDB引擎只会把R4这个记录标记为删除，之后要再插入ID为300到600之间的记录时，可能会复用此位置，但是磁盘文件大小不会缩小，如果删掉了一个数据页上所有数据，整个数据页就可以被复用

注意：**数据页复用跟记录复用不同**

#### 例如：

pageA 中删除数据R4，那么再插入一个值为400的R6是可以复用这个位置的，但是如果再插入一个值为800的记录，就不能复用这个位置

如果页分裂后，经过大量的增删改查，表会留下很多空洞

### 重建表

想要收缩A表的空洞，可以新建一个与A表结构相同的B表，然后一行行地读出数据插到B表中去

`alter table A engine=InnoDB  `

#### Online DDL

可以在重建表的过程中允许对表的更新

主要是通过生成一个临时文件，过程中所有对A的操作都记录在一个日志文件中，临时文件生成后，将日志文件的操作应用到临时文件，用这个临时文件替换原表

#### Online 和 inplace

inplace：没有将数据挪动到临时表，是一个“原地”操作

DDL过程如果是online的，就一定是inplace的

但inplace的DDL，可能不是Online，有的过程会阻塞更新操作

#### optimize table、analyze table 和 alter table

- alter table t engine = InnoDB 即为重建

- analyze不是重建表，只是对表的索引信息重新做统计，没修改数据，这个过程加了MDL读锁
- optimize table t 等于 recreate+analyze。  

## 14.count(*)这么慢，我该怎么办？

### count的实现方式

- MyISAM引擎把一个表的总行数存在了磁盘上，因此执行count(*)的时候会直接返回这个数，效率很高；
- *而InnoDB引擎就麻烦了，它执行count(*)的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。  

由于MVCC的特殊性造成的

#### 用缓存系统保存计数

Redis记录每次插入删除行数后的行数值，但会存在逻辑上的不精确

A——插入一行数据R——————————————————————Redis计数加1

B——————————————读Redis计数—————————————————

这样就会造成读出来的计数比实际上少，反之也会有问题

**可以将这个Redis值放入一张计数表中**

可以利用事务特性解决上面的问题

#### 不同的count用法

- count（主键ID）
  - 遍历整张表，把每一行ID值都取出来，返回给server层，server层拿到后，判断是不可能为空的，就按行累加
- count（1）
  - 遍历整张表，但不取值。server层对返回的每一行，放一个数字1进去，判断不可能不为空，按行累加
- count（字段）
  - not null字段，一行行地从记录里读出字段，判断不能为null,按行累加
  - null字段，要把值取出来判断一下，不是null才累加
- count(*)
  - 不会把全部字段取出来，专门做优化，不取值

效率排序：count(字段)<count(主键id)<count(1)≈count(*)  

建议使用count(*)  

## 15.答疑（一）

### 为什么不能只要redo log 不要binLog?

- 因为binlog有着redo log无法替代的功能。
  - 一个是归档。 redo log是循环写，写到末尾是要回到开头继续写的。这样历史日志没法保留， redo log也就起不到归档的作用。
  - 一个就是MySQL系统依赖于binlog。 binlog作为MySQL一开始就有的功能，被用在了很多地方。其中， MySQL系统高可用的基础，就是binlog复制。
  - 还有很多公司有异构系统（比如一些数据分析系统），这些系统就靠消费MySQL的binlog来更新自己的数据。关掉binlog的话，这些下游系统就没法输入了  

### 为什么不能只要binLog 不要redo log?

无法提供崩溃恢复能力

整个事务中写了两次binlog，第一次写完成功，第二次写完还没commit时，系统crash了，第一次被判定已经提交成功了，那么第一次就无法回滚

## 16.讲“orderby”是怎么工作的

### 全字段排序

MySQL会给每个线程分配一块sort_buffer内存用于排序

![image-20200214141625642](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200214141625642.png)

执行`select city,name,age from t where city='杭州' order by name limit 1000 ;  `的具体流程如下：

-  初始化sort_buffer，确定放入name、 city、 age这三个字段；
-  从索引city找到第一个满足city='杭州’条件的主键id，也就是图中的ID_X；
-  到主键id索引取出整行，取name、 city、 age三个字段的值，存入sort_buffer中；
-  从索引city取下一个记录的主键id；
-  重复步骤3、 4直到city的值不满足查询条件为止，对应的主键id也就是图中的ID_Y；
-  对sort_buffer中的数据按照字段name做快速排序；
-  按照排序结果取前1000行返回给客户端。  

![image-20200214141743700](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200214141743700.png)

如果排序需要的数据量小于 `sort_buffer_size`（MySQL为排序开辟的内存），就在内存中完成，如果排序数据量大，内存放不下，就得用临时文件辅助排序

### rowid排序

如果MySQL认为排序单行长度太大（返回字段很多，内存中能同时存放的行数很少）

` SET max_length_for_sort_data = 16;  `如果单行长度超过16，认为单行太大

执行流程变为：

- 初始化sort_buffer，确定放入两个字段，即name和id；
- 从索引city找到第一个满足city='杭州’条件的主键id，也就是图中的ID_X；
- 到主键id索引取出整行，取name、 id这两个字段，存入sort_buffer中；
- 从索引city取下一个记录的主键id；
- 重复步骤3、 4直到不满足city='杭州’条件为止，也就是图中的ID_Y；
- 对sort_buffer中的数据按照字段name进行排序；
- .遍历排序结果，取前1000行，并按照id的值回到原表中取出city、 name和age三个字段返回给客户端。  

### 全字段排序VSrowid排序

如果内存足够大，会优先选择全字段排序，把需要的字段先放到sort_buffer中，排序后直接从内存中返回查询结果，不回原表取数据，如果内存实在不够，才用rowid排序

**内存够，就要多利用内存，尽量减少IO磁盘访问**

可以使用覆盖索引、联合索引优化排序，让数据入库时本身就是排好序的，但这种做法要进行权衡，维护索引是有代价的

## 17.如何正确地显式随机消息

从一个表中随机取出几个行，如何正确地实现？

### 内存临时表

`mysql> select word from words order by rand() limit 3;  `

**使用explain查看语句执行情况**

- Extra字段显示Using temporary，表示的是需要使用临时表
- Using filesort，表示的是需要执行排序操作

#### 语句流程

- 创建一个临时表。这个临时表使用的是memory引擎，表里有两个字段，第一个字段是double类型，为了后面描述方便，记为字段R，第二个字段是varchar(64)类型，记为字段W。并且，这个表没有建索引  
- 从words表中，按主键顺序取出所有word值。对每个word值，用rand()函数生成一个0-1之间的小数，把这个小村和word存入临时表地R和W字段中。扫描了10000行
- 临时表有10000行，在这个无索引的内存临时表上，按字段R排序
- 从内存临时表中一行行取出R值和位置信息，分别存入sort_buffer两个字段里，又对临时表扫描了一遍，扫描行数累计20000
- sort_Buffer中按R值排序
- 排序完毕，取出前3个结果位置信息，依次到内存临时表中取出word值，返回客户端

共扫描了20003行

### MySQL如何定位 一行数据 ？

#### rowid：每个引擎用来唯一标识数据行的信息

- 对于有主键的InnoDB表来说，这个rowid就是主键ID；
- 对于没有主键的InnoDB表来说，这个rowid就是由系统生成的；
- MEMORY引擎不是索引组织表。在这个例子里面，你可以认为它就是一个数组。因此，这个rowid其实就是数组的下标  

### 磁盘临时表

`tmp_table_size  `限制了内存临时表的大小，默认16M。如果临时表大小超过这个数值，**内存**临时表就会转成**磁盘**临时表

#### 优先队列算法

- 对待排序的（R，rowid），先取前三行，构造成一个堆
- 取下一行（R1，rowid1），跟堆中最大的R比较，R1小于R，用这一行代替它
- 重复第二步，知道全部行都完成比较

#### 用优先队列算法还是临时表的归并排序算法？

取决于`sort_buffer_size`的大小，如果维护的堆过大，比如设置前1000行而不是前3行，那么就只能用归并排序算法

### 随机排序方法

如果仅随机选一个word值，如何做？

- 随机主键ID法

  - 取得主键ID的最大值M和最小值N
  - 随机函数生成一个MN之间的数X
  - 取不小于X的第一个ID的行

  效率很高，不用扫描全表。但选择每一行的概率不一样

  因为假如有4个ID，1，2，4，5。此时ID中有空洞，那么选到ID=4的概率就是其他行的两倍

  优化：

  - 取得整个表的行数C
  - 取Y = floor(C * rand())，floor函数向下取整
  - 再用limit Y,1取得一行

  解决了概率不均衡问题

- 随机取3个word值

  - 取整个表的行数 记为C
  - 根据相同随机方法得到 Y1、Y2、Y3
  - 再执行3个limit Y，1语句得到三行数据

## 18.为什么这些SQL语句逻辑相同，性能却差异巨大

### 案例一：条件字段函数操作

对索引字段做函数操作，可能会破坏索引值的有序性，优化器就决定放弃走树搜索功能

条件` where month(t_modifed)=7;  `尽量改成：

`where
-> (t_modifed >= '2016-7-1' and t_modifed<'2016-8-1') or
-> (t_modifed >= '2017-7-1' and t_modifed<'2017-8-1') or
-> (t_modifed >= '2018-7-1' and t_modifed<'2018-8-1');  `



### 案例二：隐式类型转换

**在MySQL中，字符串和数字做比较的话，是将字符串转换成数字**

这时候如果将字符串类的索引与数字进行比较，那么就自动将索引转换成数字

`mysql> select * from tradelog where tradeid=110717;  `

由于 `tradeid`是varchar类型，这条语句相当于

`mysql> select * from tradelog where CAST(tradid AS signed int) = 110717;  `

就触发了上面的规则：对索引字段做了函数操作

### 案例三：隐式字符编码转换

也是连接过程中要求在被驱动表的索引字段上加函数操作  

### 对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。  

## 19.为什么我只查一行的语句，也执行这么慢

### 第一类：查询长时间不返回

`mysql> select * from t where id=1;`

`show processlist`可以查看语句处于的状态

#### 等MDL锁

查询`sys.schema_table_lock_waits`表，找出造成阻塞的process id，将这个连接用kill命令断开

#### 等flush

有一个flush tables命令被别的语句堵住了，然后它又堵住了我们的select语句

#### 等行锁

查询`sys.innodb_lock_waits `表

`mysql> select * from t sys.innodb_lock_waits where locked_table=`'test'.'t'`\G`

### 第二类：查询慢

`mysql> select * from t where c=50000 limit 1;`

由于c上没有索引，只能走ID主键扫描，要扫描5万行，数据量大起来，执行时间线性增长



- 当前读和一致性读
- `mysql> select * from t where id=1；`
- `select * from t where id=1 lock in share mode;`
- 带锁语句执行更快
- 看下面的事务过程

![image-20200214165133148](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200214165133148.png)

- 带 lock in share mode 的SQL语句，是当前读，会直接读到 update 100万次后的结果，速度很快
- 而不带锁的语句，是一致性读，需要从100万次更新后的结果，依次执行undo log，回滚100万次

## 20.幻读是什么，幻读有什么问题

### 幻读是什么？

查看下面的场景

![image-20200214172054176](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200214172054176.png)

- Q1返回ID=5的这一行
- Q2返回ID=5和ID=0的两行
- Q3返回ID=0，ID=1，ID=5这三行
- **Q3读到ID=1的这一行，被称为“幻读”**

#### 幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行

#### 注意：

- 普通查询在**可重复读**隔离级别下是快照读，不会看到别的事务插入数据，幻读在“当前读”下才会出现
- 上面B事务中，修改的结果被A看到，不算幻读。**幻读专指“新插入的行”**

### 幻读的问题

#### 语义上

破坏了行锁声明，刚开始锁住了d=5的这一行(ID=5)，但B事务可以修改ID=0的这一行，修改完后，d=5，这个时候，这一行的修改就破坏了加锁声明

#### 数据一致性问题

如图，A事务中加入了一句`update t set d=100 where d=5`

![image-20200214173151579](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200214173151579.png)

但写入binlog时，事务A最终提交是在T6时刻，所以就会造成把B和C事务修改和插入的行一起给改变

#### 引入原因

只给d=5这一行加锁导致的

- 解决：给所有行都加上锁
- 问题：如果后来插入的那行还不存在，那就根本谈不上给它加锁

所以，即使把所有记录都加上锁，还是阻止不了新插入的数据

### 如何解决幻读？

#### 间隙锁（Gap Lock）

```mysql
CREATE TABLE `t` (
`id` int(11) NOT NULL,
`c` int(11) DEFAULT NULL,
`d` int(11) DEFAULT NULL,
PRIMARY KEY (`id`),
KEY `c` (`c`)
) ENGINE=InnoDB;
insert into t values(0,0,0),(5,5,5),
(10,10,10),(15,15,15),(20,20,20),(25,25,25); 
```

插入六个记录，产生了7个间隙，如下图

![image-20200214173835258](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200214173835258.png)

这时候执行`select * from t where d=5 for update  `时，不光加了6个行锁，还加了7个间隙锁

**跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作  ，间隙锁之间不存在冲突**

**间隙锁和行锁合称next-key lock**  

- 前开后闭区间
- 使用`select * from t for update`可以将整个表所有记录锁起来，形成了7个前开后闭区间：
- (-∞,0]、 (0,5]、 (5,10]、 (10,15]、 (15,20]、 (20, 25]、 (25, +suprenum]  

#### 问题：

**间隙锁导致同样的语句会锁住更大的范围，影响并发度**

### 其他方法

把隔离级别改成 读提交 ，同时解决数据和日志不一致问题，把binlog格式设置为row

## 21.为什么我只改一行语句，锁那么多？

### 两个原则，两个优化，一个bug

- 原则1：加锁的基本单位是next-key lock 
- 原则2：查找过程中访问到的对象才会加锁
- 优化1：索引上的等值查询，给唯一索引加锁时，next-key lock退化为行锁
- 优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候， next-key lock退化为间隙锁  
- bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止  

## 22.MySQL有哪些“饮鸩止渴”提高性能的方法

### 短连接风暴

一旦数据库处理的慢一点，这些短连接数量有可能就会暴涨

#### 方案

**处理掉占着连接但不工作的线程**

- max_connections的计算，不是看谁在running，是只要连着就占用一个计数位置  

- 有损失，优先断开事务外空闲的连接

**减少连接过程的消耗**

- 有的业务代码会短时间内先大量申请数据库连接做备用
- 可以让数据库跳过权限验证阶段：重启数据库，使用`–skip-grant-tables`参数启动  
- 风险极高，不建议使用

### 慢查询性能问题

原因：

- 索引没有设计好；
- SQL语句没写好；
- MySQL选错了索引  

#### 索引没有设计好

- 紧急创建索引

- 备库B上执行 `set sql_log_bin = off`，不写binlog，然后执行alter table语句加上索引
- 执行主备切换
- 此时主库为B，备库是A。在A上执行 `set sql_log_bin = off`，然后执行alter table语句加上索引

#### 语句没写好

- query_rewrite  功能，把输入的一种语句改写成另一模式

- 语句被错误地写成了 `select * from t where id + 1 = 10000  `

- 增加语句改写规则

- ```mysql
  mysql> insert into query_rewrite.rewrite_rules(pattern, replacement, pattern_database) values ("select *
  from t where id + 1 = ?", "select * from t where id = ? - 1", "db1");
  call query_rewrite.fush_rewrite_rules();
  ```

#### 选错了索引

- 应急方案，加上force index

### 上线前的准备工作

- 上线前，在测试环境，把慢查询日志（slow log）打开，并且把long_query_time设置成0，确保每个语句都会被记录入慢查询日志；
- 在测试表里插入模拟线上的数据，做一遍回归测试；
- 观察慢查询日志里每类语句的输出，特别留意Rows_examined字段是否与预期一致。

### QPS突增问题

- 白名单去掉
- 单独数据库用户，将这个用户删掉，断开现有连接
- 处理语句限制，将所有查询全重写为 `select  1`

## 23.MySQL怎么保证数据不丢的？

### binlog的写入机制

- 先把日志写到binlog cache ，事务提交时，再把binlog cache写到binlog文件中
- 系统给binlog cache分配了一片内存，每个线程一个，参数binlog_cache_size用于控制单个线程内binlog cache所占内存大小，超过就要暂存到磁盘
- 注意：每个线程都有自己的binlog cache ，但共用同一份 binlog文件

![image-20200215152356657](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200215152356657.png)

binlog写盘状态如上图

- write，指的是把日志写入到文件系统的page cache，并没有把数据持久化到磁盘，速度较快
- fsync，指数据持久化到磁盘。一般认为fsync才占磁盘IOPS

**write 和fsync的时机，是由参数sync_binlog控制的：**

- sync_binlog=0的时候，表示每次提交事务都只write，不fsync；
- sync_binlog=1的时候，表示每次提交事务都会执行fsync；
- sync_binlog=N(N>1)的时候，表示每次提交事务都write，但累积N个事务后才fsync

出现IO瓶颈时，可以将sync_binlog设置成一个大值提升性能。但主机发生异常重启，会丢失最近N个事务的binlog日志

### redo log 写入机制

事务还没提交时，redo log buffer有可能被持久化到磁盘

![image-20200215152746037](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200215152746037.png)

#### 三种状态

- 存在redo log buffer中，物理上是在MySQL进程内存中，就是图中的红色部分；
- 写到磁盘(write)，但是没有持久化（fsync)，物理上是在文件系统的page cache里面，也就是图中的黄色部分；
- 持久化到磁盘，对应的是hard disk，也就是图中的绿色部分。

**为了控制redo log的写入策略，InnoDB提供了`innodb_flush_log_at_trx_commit`参数，它有三种可能取值**

- 设置为0的时候，表示每次事务提交时都只是把redo log留在redo log buffer中;
- 设置为1的时候，表示每次事务提交时都将redo log直接持久化到磁盘；
- 设置为2的时候，表示每次事务提交时都只是把redo log写到page cache。
- InnoDB有一个后台线程，每隔1秒，就会把redo log buffer中的日志，调用write写到文件系统的page cache，然后调用fsync持久化到磁盘。

**注意，事务执行中间过程的redo log也是直接写在redo log buffer中的，这些redo log也会被后台线程一起持久化到磁盘。也就是说，一个没有提交的事务的redo log，也是可能已经持久化到磁盘的。**

除了每秒一次轮询操作，还有两种场景会让一个没有提交的事务redo log写入到磁盘中

- **一种是，redo log buffer占用的空间即将达到 innodb_log_buffer_size一半的时候，后台线程会主动写盘。**注意，由于这个事务并没有提交，所以这个写盘动作只是write，而没有调用fsync，也就是只留在了文件系统的page cache。
- **另一种是，并行的事务提交的时候，顺带将这个事务的redo log buffer持久化到磁盘。**假设一个事务A执行到一半，已经写了一些redo log到buffer中，这时候有另外一个线程的事务B提交，如果innodb_flush_log_at_trx_commit设置的是1，那么按照这个参数的逻辑，事务B要把redo log buffer里的日志全部持久化到磁盘。这时候，就会带上事务A在redo log buffer里的日志一起持久化到磁盘。

### LSN日志逻辑序列号

每次redo log写入长度为length 的redo log ，LSN值就会加上length

下图是三个并发事务trx1,trx2,trx3在prepare阶段，都写完redo log buffer，持久化到磁盘的过程，对应的LSN是 50 120 160

<img src="C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200215154827333.png" alt="image-20200215154827333" style="zoom: 200%;" />

- trx1第一个到达，被选为leader
- 开始写盘时，组里已经有了三个事务，LSN变为160
- 等trx1返回时，所有LSN小于等于160的redo log ，都已经被持久化到磁盘
- trx2和trx3可以直接返回

一组提交里面，组员越多，节约磁盘IOPS效果越好

#### 拖时间的优化

![image-20200215155324637](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200215155324637.png)

### WAL机制好处

- redo log和binlog都是顺序写，磁盘顺序写比随机写速度要快
- 组提交机制，大幅度江都磁盘的IOPS消耗

### 双一设置

sync_binlog 和innodb_flush_log_at_trx_commit都设置为1

**一个事务完整提交前，需要等待两次刷盘，一次是redo log（prepare 阶段），一次是binlog**，组提交机制可以尽量减少刷盘次数

## 24.MySQL怎么保证主备一致的？

### 主备基本原理

- 为什么把备库设置为只读（readonly）
  - 运营类查询会被放到备库上查，设置为只读防止误操作
  - 防止切换逻辑有bug，如切换过程中出现双写，造成主备不一致
  - 用readonly状态来判断节点的角色
- 只读如何与主库保持同步更新？
  - super权限线程无视readonly

### 同步长连接

备库B跟主库A维持一个长连接，主库A有一个线程，专门服务备库B的长连接

事务日志的同步过程：

- 备库B上-change master命令，设置主库A ip 端口 用户名 密码，从哪个位置开始请i去binLog，这个位置包含的文件名和日志偏移量
- 备库B上执行start slave,备库上启动两个线程 io_thread和sql_thread。io_thread负责与主库建立连接
- 主库A校验用户名密码后，按照备库B传来的位置，本地读取binlog发给B
- 备库B拿到binlog后，写道本地文件，称为中转日志（relay log）
- sql_thread 读取中转日志，解析出日志里的命令，执行

### binlog 的三种格式对比

statement：有可能造成主备库操作的行不一致（比如使用了两个不同索引）

row：记录了真实更改的行的主键ID，不会有主备更新不同行问题

但row格式很占空间，statement记的是操作的一个SQL语句，row格式记录的是操作行的记录，操作了几行就要记几行

mixed：statement和binlog混合使用，MySQL会自己进行判断

### 循环复制问题

主备库的双M结构：两个库互相为对方的备库

- 规定两个库的server id必须不同，若相同就不能为主备关系
- 更新的事务，binlog中记录的是自己库的server id
- 再次接收到自己库的server id时，判断相同，就不会处理，死循环中断

## 25.MySQL怎么保证高可用的？

### 主备延迟

与数据同步有关的时间点：

- 主库A执行完一个事务，写入binglog，这个时刻记为T1
- 传给备库B，把备库B接收完这个binlog的时刻记为T2
- 备库B执行完这个事务，记为T3

T3-T1就是主备延迟

### 主备延迟来源

- 有可能备库性能比主库差导致

- 备库查询压力太大
- 处理方法：
  - 一主多从，多个从库来分担读的压力
  - 通过binlog输出到外部系统，如Hadoop，让外部系统提供统计类查询的能力
- 大事务
  - 时间很长的事务，导致从库延迟
  - 大表DDL。
- 备库的并行复制能力

### 可靠性优先策略

- 判断备库B现在的seconds_behind_master，如果小于某个值（比如5秒）继续下一步，否则持续重试这一步；
- 把主库A改成只读状态，即把readonly设置为true；
- 判断备库B的seconds_behind_master的值，直到这个值变成0为止；
- 把备库B改成可读写状态，也就是把readonly 设置为false；
- 把业务请求切到备库B。

切换期间有不可用时间

### 可用性优先策略

不等主备数据同步，直接切换到库B，也就是把上面可靠性优先策略的4.5步刚开始就执行

会产生数据不一致情况

**建议使用可靠性优先策略**























## 一些技巧

`show processlist`可以查看语句处于的状态

`explain+sql语句`查看语句执行的过程
