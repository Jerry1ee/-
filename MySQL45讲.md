# MySQL45讲

## 1.一条SQL查询语句如何执行？

### MySQL基本架构示意图

![image-20200207181132597](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200207181132597.png)

- 大体分为**Server层**和**存储引擎层**


### Server层

- 连接器、查询缓存、分析器、优化器、执行器等
- 涵盖大多数核心服务功能和内置函数
- 存储过程、触发器、视图

### 存储引擎

- 负责数据存储和提取
- 架构模式：插件式的，支持InnoDB，MyISAM,Memory等

### 具体步骤

#### 1连接器

- 链接到数据库，连接器负责和客户端建立连接，获取权限、维持和管理连接

- ```mysql
  mysql -h$ip -P$port -u$user -p
  ```

- 连接建立后，即使权限被修改，也不影响已经存在的连接

- 长连接与短连接

  - 长连接：连接成功后，客户端持续有请求，一直使用同一个连接
  - 短连接：每次执行完很少的几次查询就断开连接，下次查询再重新建立一个

- 长连接导致内存涨的快：

  - 临时使用的内存管理在连接对象里，长连接累积下来不释放内存，导致内存占用增长
  - 解决：
    - 定期断开长连接，执行过一个占大内存的查询后，及时断开
    - 通过执行mysql_reset_connection  初始化连接资源

#### 2查询缓存

- 之前如果执行过这条语句，结果会以key-value形式缓存在内存中。key是查询语句，value是查询结果

- 建议不使用查询缓存，每次更新表，缓存的数据都失效了，得不偿失，将参数 query_cache_type 设置成DEMAND，这样对于默认的 SQL 语句都不使用查询缓存  ，对于需要使用的显式指定如下：

- ```mysql
  mysql> select SQL_CACHE * from T where ID=10；
  ```

- MySQL8.0**彻底删除了此功能**

#### 3分析器

- 词法分析，将字符串对应成SQL语句

#### 4优化器

- MySQL已经知道你要干什么
- 决定**多个索引使用哪个索引**；多表关联时决定**各表连接顺序**

#### 5执行器

- 权限判断
- 如果没有优化器来选择具体索引，流程如下：
  - 调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如是则将这行存在结果集中；
  - 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。
  - 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端  

## 2.一条SQL更新语句如何执行？

- 要走与查询语句一样的流程，还涉及两个重要的日志模块
  - 重做日志 redo log
  - 归档日志 binlog

### redo log 

- 每次更新都要写磁盘，磁盘也要查找，IO成本、查找成本都很高
- WAL技术 Write-Ahead Logging ，先写日志，再写磁盘，先记着，等到不忙了再进行写磁盘
- **具体过程**
  - 一条记录要更新，InnoDB先把记录写道redo log，更新内存
  - InnoDB在适当时候，将操作记录更新到磁盘里
  - 若更新记录很多，就要提前将操作记录更新到磁盘里，清空redo log，重新用于记录
  - redo log可以分为4块1GB空间，总大小4GB
  - —————checkpoint——————write pos——————|——————
    - writepos当前记录位置，边写边后移，checkpoint当前要擦除位置，擦除前要将记录更新到数据文件
    - 都是后移且循环的，两者之间是空余部分，一旦writepos追上checkpoint，就满了，必须先擦除，后移checkpoint

### binlog

- redo log 是引擎层InnoDB的日志，binlog是服务层的日志
- 之前没有InnoDB，自带引擎MyISAM没有crash-safe功能
- **区别：**
  - **binlog是server层，所有引擎都能用，redo log是InnoDB特有**
  - **redolog物理日志，记录某个“数据页上做了什么修改”；binlog是逻辑日志，记录的是该语句的原始逻辑 如 “给ID=2的这一行 c字段加1”**
  - **redo log循环写；binlog追加写，写道一定大小会切换下一个，不会覆盖之前日志**

### 具体步骤

```mysql
 mysql> update T set c=c+1 where ID=2
```



#### 1引擎取行

- 执行器先找引擎取ID=2这一行。ID为主键，引擎使用树搜索找到这一行，ID=2若在内存中，直接返回给执行器；否则，从磁盘读入内存再返回

#### 2更新写入

- 执行器拿到行数据，更新值并调用引擎接口写入新数据

#### 3更新redolog

- 引擎将新数据更新到内存，同时操作记录到redo log，redolog prepare状态，告知执行器完成，可以提交事务

#### 4binlog

- 执行器生成此操作的binlog，并写入磁盘

#### 5提交事务

- 执行器调用引擎的提交事务接口，把redo log 的prepare状态改成commit，更新完成

### 两阶段提交

- 将redo log写入拆成 prepare 和commit，为了让两份日志间逻辑一致

- binlog记录的逻辑操作，可以用来恢复数据库
- 两阶段提交为了防止 redolog binlog 只更新一个，另一个没更新的情况
- 



## 3.事务隔离

- **事务支持在引擎层实现**

### 隔离性与隔离级别

#### ACID

- Atomicity 原子性
- Consistency 一致性
- Isolation 隔离性
- Durability 持久性

#### 事务隔离级别

- 读未提交：一个事务还没提交时，它做的变更就能被别的事务看到
- 读提交：一个事务提交之后，它做的变更才能被别的事务看到
- 可重复读：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的
- 串行化：对同一行记录，写加锁，读也加锁，当读写锁冲突时，后访问事务必须等前一个事务执行完成，才能继续执行

**Oracle模式隔离级别为“读提交”**

### 事务隔离实现

**Mysql中，每条记录更新时都会同时记录一条回滚操作。记录的最新值都可以回滚到前一个值**

造成不同时刻启动的事务有不同的read-view，同一条记录在系统中存在多个版本，即数据库的**多版本并发控制（MVCC）**

- **不建议使用长事务**

  - 系统会存在很老的视图，数据库要保存它可能用到的回滚记录，占用大量存储空间
  - 占用锁资源

  

### 事务的启动方式

#### 显式启动事务语句

- begin或start transaction ，提交语句 commit，回滚语句 rollback
- set autocommit = 0 ，这个命令会将这个线程的自动提交关掉。持续存在到主动执行commit或rollback语句或断开连接
- 有些客户端连接框架连接后，会执行一个set autocommit=0，**导致长连接造成长事务**，建议使用set autocommit = 1，显式启动事务

**可以在 information_schema 库的 innodb_trx 这个表中查询长事务，**比如下面这个语句，用于查找持续时间超过 60s 的事务。******

```mysql
select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60  
```

## 4.深入浅出索引（上）

### 索引常见模型

#### 哈希表

- key-value存储数据结构，通过key找对应值value
- key通过哈希函数换算成一个特定位置，但不可避免会出现多个key换算后位置相同的情况
  - 解决方案：
  - 在后面追加一个链表，找到key位置后，如果value值不唯一，那么遍历这个链表，找到真正的value
  - 但这个链表是无序的，增加新value狠快，区间查询却很慢，因为区间查询要扫描一遍，才能完成
- **故 哈希表只适用于等值查询场景**

#### 有序数组

- 等值查询和范围查询都十分优秀；运用二分查找法，时间复杂度O（logn）
- 但插入很麻烦，需要挪动后面所有记录
- 故 **有序数组索引只适用于静态存储索引**

#### 二叉搜索树

- 为了维持O（logn）的查询复杂度，需要保持该树是平衡二叉树
- 但由于索引不止在内存中，还要写到磁盘里，二叉可能会造成树过高，需要的数据块过多，导致查询变慢，所以大多使用N叉树，N取决于数据块大小
- InnoDB整数字段，N为1200，树高为4，就能存1200的3次方个值了，倘若树的一二层都在内存中，访问磁盘的次数不超过2，速度就很快

### InnoDB的索引模型

B+树

![image-20200209141320889](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200209141320889.png)

- 有k个子结点的结点必然有k个关键码；
- 非叶结点仅具有索引作用，跟记录有关的信息均存放在叶结点中。
- 树的所有叶结点构成一个有序链表，可以按照关键码排序的次序遍历全部记录。
- B+树中间节点没有data数据，同样大小磁盘可以容纳更多节点元素
- 查询性能更稳定，适用于范围查询

#### InnoDB中，表都是根据主键顺序以索引形式存放，即索引组织表

- 每一个索引在InnoDB中对应一颗B+树

- 创建一个主键列为ID，表中有字段K的表，且K上有索引

- ```mysql
  mysql> create table T(
  id int primary key, 
  k int not null, 
  name varchar(16),
  index (k))engine=InnoDB;
  ```

- 表中R1~R5的(ID,k)值分别为(100,1)、(200,2)、(300,3)、(500,5)和(600,6)，两棵树的示例示意图如下。

- ![image-20200209141820844](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200209141820844.png)

- 根据叶子节点的内容，索引分为主键索引和非主键索引

  - 聚簇索引（主键索引）：存储整行数据
  - 二级索引（非主键索引）：存储内容是主键的值

- 主键索引，只需要搜索ID这棵B+树；如果二级索引，搜索普通索引树后拿到主键，还要再进行一次搜索，这称为**回表**

### 索引维护

- 如果插入主键值比当前所有主键都大，那么就直接插入；如果值在中间，就要挪动后面的数据。可能会产生页分裂操作，也会降低页的利用率
- 一般建议采用自增主键
- 除非只有一个索引，且是唯一索引，才用非自增字段做索引（key-value）

### 为什么采用B+树?

- 文件大，不可能都放在内存上，要存入磁盘，B+树的结构很适合磁盘读写
- B+树中间节点没有data数据，同样大小磁盘可以容纳更多节点元素
- 可以将所有叶子节点进行串联，遍历即可获取全部数据

## 5.深入浅出索引（下）

### 覆盖索引

**避免回表的一种方法**,例子如下：

```mysql
mysql> create table T (
ID int primary key,
k int NOT NULL DEFAULT 0, 
s varchar(16) NOT NULL DEFAULT '',
index k(k))
engine=InnoDB;

insert into T values(100,1, 'aa'),(200,2,'bb'),(300,3,'cc'),(500,5,'ee'),(600,6,'ff'),(700,7,'gg');

select * from T where k between 3 and 5;
```

每次根据k查出相应ID，还要回表到主键索引B+树上搜索，如果将语句改为

```mysql
select ID from T where k between 3 and 5;
```

只需要查询ID值，ID值存在K索引树上了，可以直接提供查询结果不用回表，这就是覆盖索引

可以建立联合索引来实现 **覆盖索引**，查询条件是**普通索引或联合索引的最左原则字段**，查询结果是**联合索引字段或主键**，都不用回表操作

### 最左前缀原则

以 name_age 联合索引为例，要查询的所有名字第一个字为 “张”，sql语句为"where name like  ‘张%’ "，满足最左前缀就可以用索引加速检索

#### 如何安排索引内的字段顺序？

- **第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。**
  - 如果已经有了(a,b)这个索引，而还需要b索引，不需要a索引，就不用再建立b索引了，直接将(a,b)调整为(b,a)，这样通过顺序调整，少维护了一个索引

### 索引下推

MySQL5.6引入索引下推优化，**对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数**

```mysql
mysql> select * from tuser where name like '张%' and age=10 and ismale=1;
```

**此时下推到 age=10，先把 age不为10的过滤掉，再取回表，减少了回表次数**

### 为什么要重建索引?

有时候因为索引被删除，或者页分裂，导致数据页有空洞，利用率低，重建索引可以将数据重新顺序插入，提高页面利用率，

有时候定期删除早期数据，表的内容很小，可之前的索引却占很大空间，这时用

```mysql
alter table T engine=InnoDB 
```

重建索引，可以节省空间

## 6.全局锁和表锁

处理并发问题

### 锁的分类（按加锁范围）

#### 全局锁

- 对整个数据库实例加锁，语句如下：

- ```mysql
  Flush tables with read lock ;(FTWRL)
  ```

- 无法进行更新，定义的语句或事务

- 典型应用场景：**全局逻辑备份**

- **视图的作用：**

  - 权限控制：某几列允许查询，其他列不允许
  - 简化复杂查询：用视图代替join查询数据，将不同表的字段组合在一起

- 可以通过 可重复读隔离级别开启事务，达到一致性视图的目的

- 对于不支持事务的引擎，只能使用FTWRL，支持事务使用参数 `-single-transaction`即可

- 为什么不用`set global readonly = true`?

  - readonly的值会被做其他逻辑，比如判断库是主库还是备库，修改其值影响很大
  - FTWRL命令后异常断开，MySQL会自动释放这个全局锁，整个库回到正常可更新状态，但设置为readonly后，会一只保持不可写状态，风险较高

#### 表级锁

MySQL中表级别锁有两种：**表锁**和**元数据锁**

##### 表锁

语法：`lock tables ...read/write;`

- 与FTWRL类似，可以用unlock tables 主动释放锁，也可在客户端断开时自动释放

**元数据锁 MDL（metadata lock）**

- 不需要显式使用，默认加的

- 读锁间不互斥，多个线程可同时对一张表进行增删改查
- 写锁间互斥，读写锁间也互斥，一个线程要给表加字段，另一个线程同时也要加/或查询字段，要等到前面的线程执行完才可以

**如何安全给小表加字段？**

- 防止长事务的出现，操作数据库时规定不要长事务；在MySQL的information_schema库的innodb_trx表中，删除对应长事务
- 对于热点表，在alter table语句里设定等待时间，拿不到MDL锁也不要阻塞



## 7.行锁功过：怎么减少行锁对性能的影响？

### 两阶段锁

**两阶段锁协议：**InnoDB事务中，行锁在需要时才加上，但要等到事务结束时才释放

#### 设计标准

如果事务中需要锁多个行，要把最可能造成锁冲突，影响并发度的锁尽量往后放

### 死锁和死锁检测

事务A修改id=2的行，这时事务B修改id=1的行，此时两个事务都在进行中；

然后事务A想要修改id=1的行，事务B想要修改id=2的行，此时两个事务依然都在进行中；

那么两个行都被锁住，且都在等对方释放资源，这就是死锁

- 解决：
  - 直接进入等待，直到超时（参数innodb_lock_wait_timeout来设置）
  - 发起死锁检测，主动回滚死锁链条中某一事务（参数innodb_deadlock_detect= on）
- 一般采取主动死锁检测

#### 热点行导致性能问题

每个新来的线程都向修改同一行，都要判断自己是不是会造成死锁，每次都要进行死锁检测，耗费很大的性能

- 解决：
  - 确保一定不会死锁，临时把死锁检测关掉
  - **控制并发度：可以在中间件中实现**，或者在MySQL中，对于相同行的更新，在进入引擎之前排队
  - 将一行改成逻辑上的多行来减少锁冲突：将1个记录改成10个记录的总和，每次随机更新10个中的1个

## 8.事务到底是隔离的还是不隔离的？

可重复读各级级别，事务T启动时会创建一个视图read-view，这时候其他事务修改数据，事务T看到的依然和启动时一样

![image-20200209175122564](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200209175122564.png)

### 事务的启动时机

- **begin/start transaction 命令并不是一个事务的起点**，在执行到它们之后的第一个操作InnoDB表的语句，事务才真正启动。
- 如果想马上启动一个事务，使用`tart transaction with consistent snapshot`

### MySQL的视图

- 一种是view ：一个用查询语句定义的虚拟表，调用时执行查询语句并生成结果，创建语法create view ...，查询方法与表一样
- 另一个InnoDB在实现MVCC时用到的一致性读视图，即consistent read view ，用于支持**读提交**和**可重复读**隔离级别的实现

### 快照在MVCC里如何工作？

#### 可重复读隔离级别下，事务启动时就“拍了个快照”

- InnoDB中，每个事务有一个唯一的事务ID（transaction ID），事务开始时向InnoDB事务系统申请的，严格按申请顺序递增
- 数据表中每行记录，有多个版本（row），每个版本有自己的row trx_id
- 如下所示，一个记录连续被多个事务更新：

![image-20200209180846201](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200209180846201.png)

**事务启动时，在其启动前的数据版本它认可，在其启动后生成的就不认，必须要找到上一个可见版本（在其启动之前的数据版本）**，找不到就一直往前找

实现：

- InnoDB为每个事务构造一个数组，保存这个事务启动瞬间，当前活跃的所有事务ID，活跃指启动了还没提交
- 数组中，事务ID的最小值记为低水位，系统里面已创建过的事务ID的最大值加一记为高水位
- 这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）
- 数据版本的可见性规则，就是基于数据的row trx_id和这个一致性视图对比结果得到的
- ![image-20200209184120600](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200209184120600.png)
- 对于当前事务的启动瞬间，一个数据版本的row trx_id有以下几种可能
  - 落在绿色部分：已提交事务或当前事务自己生成的，数据可见
  - 红色部分：将来启动的事务生成的，不可见
  - 黄色部分：
    - 若row trx_id在数组中，表示这个版本是由还没提交的事务生成的，不可见
    - 若row trx_id不在数组中，表示这个版本是已经提交了的事务生成的，可见
- 所有数据都有多个版本，实现了”秒级创建快照“

#### 总结

一个数据版本，对于一个事务视图来说，除了自己的更新总是可见外，有三种情况：

1）版本未提交，不可见

2）版本已提交，但是是在视图创建后提交的，不可见

3）版本已提交，而且是在视图创建前提交的，可见

### 更新逻辑



- #### 当前读：

  - 更新数据都是先读后写的，这个读，只能读当前的值，称为”当前读“
  - 当前读只管读当前的真实值，不考虑其他的

- **InnoDB的行数据有多个版本，每个数据版本有自己的row trx_id，每个事务或者语句有自己的一致性视图。普通查询语句是一致性读，一致性读会根据row trx_id和一致性视图确定数据版本的可见性。**

  - 对于可重复读，查询只承认在事务启动前就已经提交完成的数据；
  - 对于读提交，查询只承认在语句启动前就已经提交完成的数据；
  - 当前读，总是读取已经提交完成的最新版本；

## 9.普通索引和唯一索引，怎么选择？

### 查询过程

执行语句

```mysql
select id from T where k=5;
```

在索引树上的查找过程，先从B+树根节点开始，按层搜索到叶子节点，数据页内部根据二分法定位记录

- 普通索引，找到满足条件的第一个记录，还要查找下一个，知道碰到第一个不满足的为止
- 唯一索引，由于定义了索引唯一性，找到第一个满足的就停止检索

实际上，**性能差距微乎其微**，因为InnoDB数据按数据页为单位读写。读一条记录，不是将这个记录从磁盘中读出来，是以页为单位，将其整体读入内存，所以再同一数据页中读下一个记录，耗费的时间可以忽略不计

### 更新过程

#### change buffer：

1.更新数据页时，数据页在内存中，就直接更新；如果数据页不在内存中，在不影响一致性的前提下，InnoDB会将这些更新操作缓存在change buffer中，这就不需要从磁盘中读入这个数据页。

2.当下次查询需要访问这个数据页时，将数据页读入内存，然后执行change buffer中与这个页相关的操作

- change buffer 也可以持久化

3.将change buffer 中的操作应用到原数据页，得到最新结果的过程称为purge。除了访问该数据页会触发purge，系统有后台线程会定期purge。

**好处：**将更新操作先记录在change buffer中，减少读磁盘，语句执行速度明显提升；

数据读入内存要占用 buffer pool，这种方式还能避免占内存，提高内存利用率

- 使用场景：只有普通索引能用，因为唯一索引要先判断表中是否存在重复记录，必须要将数据页读入内存

#### 更新目标页过程：

- 更新的目标页在内存中：

  - 唯一索引找到位置，判断冲突，插入值
  - 普通索引找到位置，插入值

  只是判断与否的问题

- 要更新的目标页不在内存中：

  - 唯一索引需要将数据页读入内存，判断冲突，插入值
  - 普通索引将更新记录在change buffer，结束

  普通索引性能提升明显

### change buffer 使用场景

- 由于真正更新数据的阶段是purge，所以在数据页purge之前，changebuffer 记录的变更越多，收益越大
- 因此，**写多读少的业务**，change buffer效果很好，**比如账单类，日志类**
- 相反的，**写入后马上查询的业务**，change buffer **不太适合**

### 索引的选择和实践

- #### 建议选择普通索引，如果更新后经常查询，就关闭change buffer

### change buffer 和 redo log

- redo log主要节省 随机写磁盘的IO消耗
- change buffer主要节省 随机读磁盘的IO消耗

## 10.MySQL为什么有时候会选错索引？

### 优化器逻辑

**选择索引是优化器的工作**

### 扫描行数的判断

#### 区分度

一个索引上不同值越多，索引区分度越好，一个索引上不同值的个数，称之为“基数”

#### 基数的由来

采样统计，默认选N个数据页，统计页上的不同值，得到一个平局值，乘这个索引的页面数

变更行数超过1/M时，自动触发重新做一次索引统计

**可以用`analyze table t`来修正统计信息，只针对索引统计信息不准确的问题**

优化器认为直接查主键，虽然行数较多，但省去了回表的消耗，有时候这样的决策是错误的

### 索引选择异常和处理

- #### 采用force index 强行选择一个索引

  - 局限性太大

- #### 修改语句，引导MySQL使用我们期望的索引

- #### 新建索引/删掉索引

## 11.怎么给字符串字段加索引

```
mysql> create table SUser(
ID bigint unsigned primary key,
email varchar(64), 
... 
)engine=innodb; 
```

由于要使用邮箱登录，所以业务代码中一定会出现类似于这样的语句：

```
mysql> select f1, f2 from SUser where email='xxx';
```

从第4和第5篇讲解索引的文章中，我们可以知道，如果email这个字段上没有索引，那么这个语句就只能做全表扫描。

比如，这两个在email字段上创建索引的语句：

```
mysql> alter table SUser add index index1(email);
或
mysql> alter table SUser add index index2(email(6));
```

**第一个语句创建的index1索引里面，包含了每个记录的整个字符串；**

**而第二个语句创建的index2索引里面，对于每个记录都是只取前6个字节**

**前缀索引占用空间小，但可能会增加额外的记录扫描次数**

### 前缀索引使用

- 定义好长度，就既能节省空间，又不用额外增加态度查询成本

- 让前缀索引在尽可能短的情况下区分度尽量高

- 首先，你可以使用下面这个语句，算出这个列上有多少个不同的值：

  ```
  mysql> select count(distinct email) as L from SUser;
  ```

  然后，依次选取不同长度的前缀来看这个值，比如我们要看一下4~7个字节的前缀索引，可以用这个语句：

  ```
  mysql> select 
    count(distinct left(email,4)）as L4,
    count(distinct left(email,5)）as L5,
    count(distinct left(email,6)）as L6,
    count(distinct left(email,7)）as L7,
  from SUser;
  ```

  当然，使用前缀索引很可能会损失区分度，所以你需要预先设定一个可以接受的损失比例，比如5%。然后，在返回的L4~L7中，找出不小于 L * 95%的值，假设这里L6、L7都满足，你就可以选择前缀长度为6。

### 前缀索引对覆盖索引的影响

**使用前缀索引就用不上覆盖索引的优化功能**，因为它必定要回表查当前主键对应的行中当前的索引值是否完全相同而不是只有前缀相同

### 其他方式

以存储身份证号为例，如果管理的是一个市的公民信息系统，那么身份证号前6为区分度为0，因此前缀索引很难发挥

#### 倒序存储

将身份证号倒过来存储

#### 使用hash字段

使用crc32()函数，将身份证号变为校验码字段存储，再以校验码为索引

#### 注意：都不支持范围查询，只支持等值查询

#### 区别：

- 占用额外空间：倒序存储方式在主键索引上，不会消耗额外存储空间
- CPU消耗：reverse函数额外消耗CPU资源比crc32函数小
- 查询效率：hash字段方式查询更稳定，倒序存储本质还是前缀索引，还是会增加扫描行数

## 12.为什么我的MySQL会“抖”一下？  

**当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。**

**内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”**  

平时执行很快的更新操作：写日志和内存

抖动：刷脏页

### 刷脏页的时刻

#### redo log 写满

checkpoint移动，移动区间所有脏页都要flush进磁盘

#### 内存不足

淘汰数据页，给新数据页使用

#### 系统空闲时刻

#### MySQL正常关闭

### 四种时刻分析

- 第一种“redo log 写满”，尽量避免，此时不接收更新，阻塞

- 第二种“内存不足”，是常态，InnoDB用缓冲池（buffer pool）管理内存，缓冲池内存页的三种状态
  - 还没有使用
  - 使用了且干净页
  - 使用了且脏页
- 影响性能的刷脏页操作：
  - 查询要淘汰的脏页个数太多，导致查询影响时间明显变长
  - 日志写满，更新全部堵住，写性能跌至0

### InnoDB刷脏页的控制策略

`innodb_io_capacity   `参数，对应磁盘的IOPS，尽全力刷脏页

考虑：

- 脏页比例 `innodb_max_dirty_pages_pct  `脏页比例上限，默认值75%，不要让它经常接近75%
- redo log 写盘速度

### 其他

`innodb_flush_neighbors`：刷脏页时，如果这个值为1，会找到邻居脏页一起刷掉，且这个逻辑可以蔓延

- 对机械硬盘优化较大，减少随机IO
- SSD这种IOPS较高的设备，IOPS不是瓶颈

## 13.为什么表数据删掉一半，表文件大小不变？ 

### 参数`innodb_file_per_table`

表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数`innodb_file_per_table `控制的：

- 这个参数设置为 OFF 表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起
- 这个参数设置为 ON 表示的是，每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中

一个表单独存储为一个文件更容易管理，不需要时，直接drop table，会直接删除这个文件；如果放在共享空间，表删掉了空间也不会回收

推荐设置为 ON

### 数据删除流程

![image-20200213150330269](C:\Users\lzy\AppData\Roaming\Typora\typora-user-images\image-20200213150330269.png)

如果删除R4这个记录，InnoDB引擎只会把R4这个记录标记为删除，之后要再插入ID为300到600之间的记录时，可能会复用此位置，但是磁盘文件大小不会缩小，如果删掉了一个数据页上所有数据，整个数据页就可以被复用

注意：**数据页复用跟记录复用不同**

#### 例如：

pageA 中删除数据R4，那么再插入一个值为400的R6是可以复用这个位置的，但是如果再插入一个值为800的记录，就不能复用这个位置

如果页分裂后，经过大量的增删改查，表会留下很多空洞

### 重建表

想要收缩A表的空洞，可以新建一个与A表结构相同的B表，然后一行行地读出数据插到B表中去

`alter table A engine=InnoDB  `

#### Online DDL

可以在重建表的过程中允许对表的更新

主要是通过生成一个临时文件，过程中所有对A的操作都记录在一个日志文件中，临时文件生成后，将日志文件的操作应用到临时文件，用这个临时文件替换原表

#### Online 和 inplace

inplace：没有将数据挪动到临时表，是一个“原地”操作

DDL过程如果是online的，就一定是inplace的

但inplace的DDL，可能不是Online，有的过程会阻塞更新操作

#### optimize table、analyze table 和 alter table

- alter table t engine = InnoDB 即为重建

- analyze不是重建表，只是对表的索引信息重新做统计，没修改数据，这个过程加了MDL读锁
- optimize table t 等于 recreate+analyze。  

## 14.count(*)这么慢，我该怎么办？

### count的实现方式

- MyISAM引擎把一个表的总行数存在了磁盘上，因此执行count(*)的时候会直接返回这个数，效率很高；
- *而InnoDB引擎就麻烦了，它执行count(*)的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。  

由于MVCC的特殊性造成的

#### 用缓存系统保存计数

Redis记录每次插入删除行数后的行数值，但会存在逻辑上的不精确

A——插入一行数据R——————————————————————Redis计数加1

B——————————————读Redis计数—————————————————

这样就会造成读出来的计数比实际上少，反之也会有问题

**可以将这个Redis值放入一张计数表中**

可以利用事务特性解决上面的问题

#### 不同的count用法

- count（主键ID）
  - 遍历整张表，把每一行ID值都取出来，返回给server层，server层拿到后，判断是不可能为空的，就按行累加
- count（1）
  - 遍历整张表，但不取值。server层对返回的每一行，放一个数字1进去，判断不可能不为空，按行累加
- count（字段）
  - not null字段，一行行地从记录里读出字段，判断不能为null,按行累加
  - null字段，要把值取出来判断一下，不是null才累加
- count(*)
  - 不会把全部字段取出来，专门做优化，不取值

效率排序：count(字段)<count(主键id)<count(1)≈count(*)  

建议使用count(*)  

## 15.答疑（一）

### 为什么不能只要redo log 不要binLog?

- 因为binlog有着redo log无法替代的功能。
  - 一个是归档。 redo log是循环写，写到末尾是要回到开头继续写的。这样历史日志没法保留， redo log也就起不到归档的作用。
  - 一个就是MySQL系统依赖于binlog。 binlog作为MySQL一开始就有的功能，被用在了很多地方。其中， MySQL系统高可用的基础，就是binlog复制。
  - 还有很多公司有异构系统（比如一些数据分析系统），这些系统就靠消费MySQL的binlog来更新自己的数据。关掉binlog的话，这些下游系统就没法输入了  

### 为什么不能只要binLog 不要redo log?

无法提供崩溃恢复能力

整个事务中写了两次binlog，第一次写完成功，第二次写完还没commit时，系统crash了，第一次被判定已经提交成功了，那么第一次就无法回滚

## 16.讲“orderby”是怎么工作的

### 全字段排序

MySQL会给每个线程分配一块sort_buffer内存用于排序

